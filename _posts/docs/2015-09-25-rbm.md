---
layout: post
title: Example-Restricted Boltzmann Machine
subtitle: Example-Restricted Boltzmann Machine
category : docs
tags : [rbm, example]
---
{% include JB/setup %}

This example will show you how to use SINGA to train RBMs and  + Autoencoder model
using MNIST dataset.


This example describes a method to use deep autoencoder to reduce the
dimensionality of data. RBM model is used here to initialize of the weights of
deep autoencoder.


## Data Preparation
Go to the example/rbm/ folder for preparing the dataset. There should be a
makefile example called Makefile.example in the folder. Run the command cp
Makefile.example Makefile to generate the makefile. Then run the command make
download and make create in the current folder to download mnist dataset and
prepare for the training and testing datashard.


## Pretraining

In this example, we define 4 RBM models for pre-training. For the first 3 RBM
models, the activation probabilities of the hidden units will be used as the
visible units of higher level RBM. After the pre-training, these 4 RBMs are
“unfolded” to form encoder and decoder networks that initially use the same
weights.

### Bottom RBM
<img src="{{ BASE_PATH }}/assets/image/bottom-rbm.png" style="width: 450px"/>
<p><strong> Figure.1 - Net structure for training bottom RBM.</strong></p>


Configure a 784X1000 RBM model (RBM0, Figure 1) and save its
checkpoint to "/data/zhaojing/checkpoint/rbm0/" by configuring workspace like
following:
workspace: "/data/zhaojing/checkpoint/rbm0/"

### Second RBM
Configure a 1000X500 RBM model (RBM1, Figure 2) and load the
checkpoint of RBM0 from
"/data/zhaojing/checkpoint/rbm0/checkpoint/step6000-worker0.bin" by configuring
checkpoint_path like following:
checkpoint_path:
"/data/zhaojing/checkpoint/rbm0/checkpoint/step6000-worker0.bin".
Also it should save its checkpoint to "/data/zhaojing/checkpoint/rbm1/" by
configuring workspace like following:
workspace: "/data/zhaojing/checkpoint/rbm1/"

### Third RBM
Configure a 500X250 RBM model (RBM2, Figure 3) and load the checkpoint
of RBM1 from "/data/zhaojing/checkpoint/rbm1/checkpoint/step6000-worker0.bin"
by configuring checkpoint_path like following:
checkpoint_path:
"/data/zhaojing/checkpoint/rbm1/checkpoint/step6000-worker0.bin".
Also it should save its checkpoint to "/data/zhaojing/checkpoint/rbm2/" by
configuring workspace like following:
workspace: "/data/zhaojing/checkpoint/rbm2/"

### Top RBM
Configure a 250X30 RBM model (RBM3, Figure 4) and load the checkpoint
of RBM2 from "/data/zhaojing/checkpoint/rbm2/checkpoint/step6000-worker0.bin"
by configuring checkpoint_path like following:
checkpoint_path:
"/data/zhaojing/checkpoint/rbm2/checkpoint/step6000-worker0.bin".
Also it should save its checkpoint to "/data/zhaojing/checkpoint/rbm3/" by
configuring workspace like following:
workspace: "/data/zhaojing/checkpoint/rbm3/"

## Fine-tuning
Configure an auto encoder with 7 hidden layers (Figure 5). Load the
checkpoints of previous 4 RBM models to initialize its parameters like
following: and save its checkpoint to "/data/zhaojing/checkpoint/rbm0/" by
configuring workspace like following:
checkpoint_path:
"/data/zhaojing/checkpoint/rbm0/checkpoint/step6000-worker0.bin"
checkpoint_path:
"/data/zhaojing/checkpoint/rbm1/checkpoint/step6000-worker0.bin"
checkpoint_path:
"/data/zhaojing/checkpoint/rbm2/checkpoint/step6000-worker0.bin"
checkpoint_path:
"/data/zhaojing/checkpoint/rbm3/checkpoint/step6000-worker0.bin"
And tts checkpoint will be saved to "/data/zhaojing/checkpoint/autoencoder/" by
configuring the workspace like following:
workspace: "/data/zhaojing/checkpoint/autoencoder/"
